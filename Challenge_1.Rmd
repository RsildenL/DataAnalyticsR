---
title: "Challenge 1: General Overview and Data Treatment"
subtitle: "Data Analytics with R"
author: "Rebecca Silden Langlo, Afonso Penalva, Kevin Ganglbauer, Henrik Mülheims, Martí Pérez & Karmanpreet Singh" 
date: "22/02/2021"
      
output: 
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(pROC)
library(openair)
library(basicTrendline)
```

Reading the data
```{r , cache = TRUE}
machine_data <- fread("Data/machine_data.csv")
product_data <- fread("Data/product_data.csv")
transaction_data <- fread("Data/transactional_data.csv")
transaction_data$date <- as.Date(transaction_data$date)
merged_data <- merge(transaction_data, product_data, by.x = "product_name", by.y ="product_name")
merged_data <- merge(merged_data, machine_data, by= "machine")
```


## Question 1: Data overview
### Machines
1a) How many machines are there? 

There are 2495 vending machines in total.

1b) What percentage of them are small? 

Out of those 38% (959) are small and 62% (1536) are large vending machines.

1c) How do they distribute in terms of location type i.e. transport, petrol station?

More than half of the vending machines are placed close to transportation, while only about 14% are placed close to a petrol station. Also there is one vending machine that is not classified regarding location type.

```{r}
number_of_machines <- uniqueN(machine_data$machine)
machine_dist <- machine_data[,.(.N), by=small_machine]
machine_dist[,percent := round(N/number_of_machines, 4)]
machine_dist$type <- ifelse(machine_dist$small_machine == 1, 
                            yes = "small", no = "large")
machine_dist <- machine_dist %>% add_row(small_machine = NA, N = number_of_machines, percent = 1, type = "total") 

machine_dist[,.(type,N, percent)]
```

```{r}
machine_dist_by_location <- machine_data[,.(.N),by = location_type]
machine_dist_by_location [,percent := round(N/number_of_machines,4)]
machine_dist_by_location
```


### Products 
1d) How many products are there? Which category has the highest number of products?

There are 63 different types of products.
The category "Carbonates and energy drinks" has highest number of products (13 products).
```{r}
uniqueN(product_data$product_name)
```
```{r}
product_data[ , .(.N), by = category][ N == max(N)]
```

1e) Which category has the highest and lowest average price? And within snacks or
drinks? 

The category "Milk based" has the highest average price whereas category "Sugar Candy" has the lowest average price overall.
Within the category "Drinks", the highest average price is of "Milk based" (3.4250) and lowest is of "Juice, tea and smoothies" (2.8625).
Within the category "snack", the highest average price is of "Salty" (2.725) and lowest is of "Sugar Candy" (2.300).


Highest and lowest price in category
```{r}
product_data[ ,.(avg_price= mean(price)), by = category][avg_price == min(avg_price) | avg_price == max(avg_price)]
```

Drinks with the highest and lowest average price
```{r}
product_data[ type_drink_snack == 'drink' ,.(avg_price= mean(price)), 
                                       by = list(category, type_drink_snack)][avg_price == min(avg_price) | avg_price == max(avg_price)]
```

Snacks with the highest and lowest average price
```{r}
product_data[ type_drink_snack == 'snack' ,.(avg_price= mean(price)), 
                                       by = list(category, type_drink_snack)][avg_price == min(avg_price) | avg_price == max(avg_price)]
```

In total, there are 63 different products classified as "drink" or "snack", which are spread over 8 different categories.
"Carbonates and energy drinks" is the category with the most products, followed by the category "Chocolate based" with 11 different products. 
The "Milk based" drinks have the highest average price of 3.425, whereas "Sugar candy" snacks have the lowest average price of 2.3.

```{r}
product_dist <- product_data[,.(.N, mean_price = round(mean(price),4)), by=category][order(-N)]
product_type_dist <- product_data[,  .(.N, mean_price = round(mean(price),4)), by = .(category, type_drink_snack)][order(-mean_price)]
product_dist; product_type_dist
```

### Transactional data
In March, there are 2494 vending machines selling products, of which 1536 are big machines and 958 are small machines. The big machines have a higher average of products sold per machine per day. The higher daily sales of the big machines are a result of more extreme observations. While the maximum average daily sales for the small machines are 30, some of the large vending machines have a higher average daily turnover with a maximum of almost 60. 

From the distribution of the daily sales, it is clear that some machines have significantly more sales than others. This could indicate that some machines are strategically better placed than others. Another reason could be that the respective assortment is better.

```{r}
march <- merged_data[year(date)=='2017' & month(date)=='3',.(.N), by=.(date,machine,small_machine)]
march_avg_size <- march[,.(mean_items=mean(N)),by=.(machine, small_machine)]
march_avg<-march_avg_size[,.(avg_daily_items=sum(mean_items)/uniqueN(machine)),by=small_machine]
march_avg$type <- ifelse(march_avg$small_machine == 1, 
                            yes = "small", no = "large")
march_avg[,.(type, avg_daily_items)]
```
```{r}
boxplot(march_avg_size$mean_items,
        march_avg_size[small_machine == 1,]$mean_items, 
        march_avg_size[small_machine == 0,]$mean_items, 
        main = "Daily Sales Distribution",
        names = c("all machines", "small machines", "big machines"),
        ylab = "daily sales")
```

Snacks with the highest and lowest average price
```{r}
product_data[ type_drink_snack == 'snack' ,.(avg_price= mean(price)), 
                                       by = list(category, type_drink_snack)][avg_price == min(avg_price) | avg_price == max(avg_price)]
```


## Question 2: Plot interpretation 
![](Q2.JPG)

### General Trend
a. Is there a general trend in the number of snacks and drinks as the months progress from January to April? Is it the same for snacks and drinks? Why do you think that might be so?

The graph for drinks shows a general increase in daily_items across the available time frame. To better illustrate this (linear) trend, we have created a new plot. The graph for snacks shows no such trend. Instead, the trend line of the new plot for snacks is a horizontal line. The reason for the increasing trend for drinks could be related to seasonal consumption habits. Rising temperatures might stimulate the purchase of beverages without having an effect on the number of snack items sold. 

```{r drinks trend}
drink_trend <- merged_data[type_drink_snack == 'drink',.(avg_daily=.N/uniqueN(machine)), by=(date)][order(date)]
#plot(drink_trend$date,drink_trend$avg_daily,type = "l", main = 'Drinks per Machine per Day')

trendline(
  drink_trend$date,
  drink_trend$avg_daily,
  model = "line2P",
  Pvalue.corrected = TRUE,
  linecolor = "blue",
  lty = 1,
  lwd = 1,
  show.equation = TRUE,
  show.Rsquare = TRUE,
  show.pvalue = TRUE)
```

```{r snack trend}
snack_trend <- merged_data[type_drink_snack == 'snack',.(avg_daily=.N/uniqueN(machine)), by=.(date)][order(date)]
#plot(snack_trend$date,snack_trend$avg_daily,type = "l", main = 'Snacks per Machine per Day')

trendline(
  snack_trend$date,
  snack_trend$avg_daily,
  model = "line2P",
  Pvalue.corrected = TRUE,
  linecolor = "blue",
  lty = 1,
  lwd = 1,
  show.equation = TRUE,
  show.Rsquare = TRUE,
  show.pvalue = TRUE)
```

### Seasonal trend
b. Is there shorter time period trend as well? Is it the same for snacks and drinks? What do you think might be the cause?
* weekly seasonality for both snack and drinks
* Drinks: weekend average of 4.57 vs. weekday average of 3.39
* Snacks: weekend average of 7.25 vs. weekday average of 5.61

The vending machines are used more frequently on weekends than on the weekdays. A potential explanation for this could be that people travel more on weekends as they have more time. Thus, vending machines, especially those in close proximity of public transport, might be more highly frequented on Saturdays and Sundays.


```{r}
drink_trend[,day:=weekdays(date)]
drink_dist <- drink_trend[ , .(daily_drink = mean(avg_daily)) , by=day]
drink_dist <- drink_dist %>% add_row(day = "Weekend", daily_drink =mean(drink_trend[day=="Sunday"|day=="Saturday"]$avg_daily)) 
drink_dist <- drink_dist %>% add_row(day = "Weekdays", daily_drink =mean(drink_trend[!(day=="Sunday"|day=="Saturday"),]$avg_daily))
drink_dist$daily_drink <- round(drink_dist$daily_drink, 2)

snack_trend[,day:=weekdays(date)]
snack_dist <- snack_trend[ , .(daily_snack = mean(avg_daily)) , by=day]
snack_dist <- snack_dist %>% add_row(day = "Weekend", daily_snack =mean(snack_trend[day=="Sunday"|day=="Saturday"]$avg_daily)) 
snack_dist <- snack_dist %>% add_row(day = "Weekdays", daily_snack =mean(snack_trend[!(day=="Sunday"|day=="Saturday"),]$avg_daily))
snack_dist$daily_snack <- round(snack_dist$daily_snack, 2)

merge(snack_dist, drink_dist)
```


## Question 3: Distribution of income 
### Outliers
There are some extreme values in the distribution of income across, which could be interpreted as outliers. This means that there are some machines that generate much more revenue than others, and could be a result of a strategically good location of the vending machines. These outliers seem to be distributed across both small and big machines.
```{r}
income_small <- machine_data[small_machine==1, income_average]
income_big <- machine_data[small_machine==0, income_average]
boxplot(machine_data$income_average, income_small, income_big,
        main = "Income Distribution",
        names = c("all machines", "small machines", "big machines"),
        ylab = "income average")

summary(machine_data$income_average)  
hist(machine_data$income_average,
  xlab = "income average",
  main = "Histogram of income",
  breaks = 10)

summary(machine_data$income_average); summary(income_big) ; summary(income_small)

```
There are several ways to detect and remove outliers.
One possible way is to perform a log transformation. The log transformation would include these outliers, but decrease the impact of them significantly.
```{r}
boxplot(log(machine_data$income_average), log(income_small), log(income_big),
        main = "Income Distribution",
        names = c("all machines", "small machines", "big machines"),
        ylab = "income average")

summary(log(machine_data$income_average))
```
Another method is the Interquartile range (IQR). We will employ the commonly used Interquartile range (IQR), a measure of statistical dispersion that consists of calculating the difference between the 75th and 25th percentiles or between upper and lower quartiles, such that IQR = Q3 - Q1. 
Then an upper and lower thresholds are set by multiplying the IQR by 1.5 (a constant used to discern outliers). Any number greater than Q3 + 1.5xIQR will be identified as an outlier. In a similar way, values smaller than Q1-1.5xIQR are also classified as outliers.


```{r}
Q <- quantile(machine_data$income_average, probs=c(.25, .75), na.rm = TRUE)
iqr <- IQR(machine_data$income_average, na.rm= TRUE)

up <-  Q[2]+1.5*iqr # Upper Range (beyond which datapoints are outliers)  
low<- Q[1]-1.5*iqr # Lower Range

machine_data_clean <- subset(machine_data, machine_data$income_average > (Q[1] - 1.5*iqr) & machine_data$income_average < (Q[2]+1.5*iqr))

summary(machine_data_clean$income_average)
```
Moving forward, the income averages are chosen to be kept as they are, with no adjustment of outliers. This is done because we do not interpret the outliers as unlikely observations, although we are aware of the consequences that this may lead to more noisy predictions in the models in question 5.

### Missing values
Missing data is a very common problem that can reduce the statistical power of our data or to produce biased estimates that will invalidate our predictions.

There are 182 NA values in the income average feature. Out of theses 182 observations, 104 of them are also NA in the train average daily passengers and train average day passengers.
* no machines that have more than 1 NA
* 59% of NA's are big machines, 41% are small machines
* 50% of NA's are located close to transportation
```{r}
income_NA <- machine_data[is.na(income_average), ]
uniqueN(income_NA)

income_NA[ ,.(N = .N, porportion = .N/uniqueN(income_NA)) , by=location_type]
income_NA[ ,.(N = .N, porportion = .N/uniqueN(income_NA)) , by= small_machine]
income_NA[ ,.(N = .N, porportion = .N/uniqueN(income_NA)) , by= machine][order(-N)]
```

Option 1: Remove NA's

To deal with missing values, we can simply delete rows when a missing value occurs. Our problem is fixed, however this may affect the distribution of our data and thus the predictive capabilities of our model. The advantage of this method is that no approximation could lead to noise in the model.

```{r}
machine_remove_NA <- machine_data[!is.na(machine_data$income_average), ]
summary(machine_remove_NA$income_average)
```
Option 2: Replace NA's with Zero

Another approach could be to replace all missing values with zero. This is one way to avoid missing instances, but replacing with zero seems unreasonable as the minimum income of the income average in our data set is 31570. 
```{r}
na_zero <- machine_data
na_zero$income_average[is.na(na_zero$income_average)] <- 0

summary(na_zero$income_average)
```

Option 3: Substitute missing values with the mean income average 

A similar but more reasonable approach to deal with missing values is to replace the missing values with the mean of the income average. The advantage is that we keep these instances, but this could cause some correlation problems and affect the variability of our data.
```{r}
machine_data_replace_NA_mean <- machine_data
machine_data_replace_NA_mean$income_average[is.na(machine_data_replace_NA_mean$income_average)] <- mean(machine_data$income_average, na.rm = TRUE)
summary(machine_data_replace_NA_mean$income_average)
```

Option 4: substitute missing values with average income of machine 

For this particular situation, we decide to replace the missing value with the mean income average of the machine type and location type of the instance where we have a missing value. This is an improvement from  the overall average in the last option, as it uses the mean of machines with more similar characteristics.
```{r}
w_na <- machine_data[!is.na(machine_data$income_average), ]
#w_na$income_average[is.na(w_na$income_average)]

na_mean <- machine_data
means <- w_na %>%
         filter(is.na(location_type) == F) %>%
         select(income_average, location_type, small_machine) %>%
         group_by(small_machine, location_type) %>%
         summarize(mean = mean(income_average))

small_others <- with(means, mean[small_machine == 1 & location_type == 'others'])
small_transport <- with(means, mean[small_machine == 1 & location_type == 'transport'])
small_petrol <- with(means, mean[small_machine == 1 & location_type == 'petrol station'])

big_others <- with(means, mean[small_machine == 0 & location_type == 'others'])
big_transport <- with(means, mean[small_machine == 0 & location_type == 'transport'])
big_petrol <- with(means, mean[small_machine == 0 & location_type == 'petrol station'])

na_mean$income_average[na_mean$small_machine==1 
                       & na_mean$location_type == 'others' 
                       & is.na(na_mean$income_average)] <- small_others
na_mean$income_average[na_mean$small_machine==1 & na_mean$location_type == 'transport' & is.na(na_mean$income_average)] <- small_transport
na_mean$income_average[na_mean$small_machine==1 & na_mean$location_type == 'petrol station' & is.na(na_mean$income_average)] <- small_petrol

na_mean$income_average[na_mean$small_machine==0 & na_mean$location_type == 'others' & is.na(na_mean$income_average)] <- big_others
na_mean$income_average[na_mean$small_machine==0 & na_mean$location_type == 'transport' & is.na(na_mean$income_average)] <- big_transport
na_mean$income_average[na_mean$small_machine==0 & na_mean$location_type == 'petrol station' & is.na(na_mean$income_average)] <- big_petrol

#na_mean$income_average[is.na(na_mean$income_average)]
summary(na_mean$income_average)
```


## Question 4: Boxplot interpretation 
![](Q4.JPG)

According to this boxplot the median of the number of hotels in the machine area is 0. This means that most machines do not have any hotels in their area. In this case, the median also coincides with both the minimum and the 1st quantile. 
The 3rd quantile is 1, while the mean of the observations is 2. This is due to the fact that most of the vending machines do not have any hotels nearby, while about half of the machines that have hotels nearby (i.e. the 4th quantile) seem to have a relatively high number of hotels nearby (the maximum is 79 hotels nearby).

```{r}
boxplot(machine_data$num_hotels)
summary(machine_data$num_hotels)
```


## Question 5: Location score

In this exercise we will build a location score that tells us what’s the average daily items per machine depending on the location it is placed. This model could be used to 
a) Decide in which locations to place new machines 
b) Construct a benchmark for each machine: how much should it sell according to its location? This can be used to detect problems in machines (i.e. illumination, bad placement within a station etc.)

```{r}
machine_data[,not_trainstation:=ifelse(is.na(train_AvgDailyPassengers),1,0)]
daily_items_sold <- merged_data[, .(.N), by= .(machine, date)]
daily_items_sold <- daily_items_sold[,.(daily_sales = mean(N)), by=machine]
model_data <- merge(machine_data, daily_items_sold)

model_data$total_number_of_routes_600[is.na(model_data$total_number_of_routes_600)] <- median(model_data$total_number_of_routes_600, na.rm=TRUE)
model_data$income_average <- na_mean$income_average
summary(model_data)
```
Linear regression does not work well with missing values, in this dataset we have missing values for the total number of routes 600 and for income average. 

* For the mimssing values in the total number of routes 600, with the median of the number of routes.
* For the missing values in the income average we replace them with the categorical mean of the instance based on machine size and location type, as described as option 4 in question 3. 

### Significant variables
Do all variables show statistical significance? Which ones doesn’t? How do you know?

By checking the p-values of the coefficients, we can see that the total number of routes and number of vendex machines nearby is insignificant features. 
```{r}
m0 <- glm( daily_sales ~ small_machine + income_average + total_number_of_routes_600
     + num_hotels_45 + not_trainstation + num_vendex_nearby_300, 
    data = model_data)
summary(m0)
```

### Linear model 
Build another linear model but this time instead of using the variables “total_number_of_routes_600 use the log of that variable in base 10 calling it “log_transport”. Does this new variable show statistical significance?

By log transforming the total number of routes 600, the values becomes less extreme. This can be shown in the summary below of the original feature and the log tranformed feature, respectively 
```{r}
summary(model_data$total_number_of_routes_600)
model_data[,log_transport:= log(total_number_of_routes_600)]
summary(model_data$log_transport)
```

Create new model, including all variables but use log transport instead.

* All features are significant, including the number of vendex machines nearby  
```{r}
m1 <- glm(daily_sales ~ small_machine + income_average + log_transport
     + num_hotels_45 + not_trainstation + num_vendex_nearby_300, 
        data = model_data)
summary(m1)
```

### Cross-validation
next we train the model using a 80/20 train/test split of the dataset and a 5-fold cross validation.
```{r }
# 5 fold : Train-test split
set.seed(1)
cfolds <- 5
index <- sample(1:cfolds, nrow(model_data), replace = TRUE)

for (i in 1:5){
  train <- model_data[index !=i,]
  test <- model_data[index == i,]
  final_model <- glm(daily_sales ~ small_machine + income_average + log_transport
     + num_hotels_45 + not_trainstation + num_vendex_nearby_300, 
     data = train)
  pred_train1 <- predict(final_model, newdata = train, type = "response")
  pred_test1 <- predict(final_model, newdata = test, type = "response")
}

summary(final_model)
```

### Small machines
How many daily items less do small machines sell all other factors remaining equal?

After removing statistically non-significant variables from our model and assuming all other factors remaining equal, a machine that is small sells on average 1.667252 fewer units per day than big machines.
```{r }
final_model$coefficients["small_machine"]
```

### Number of machines nearby
What’s effect on machine sales does having other nearby machines all other factors remaining equal?

With other machines nearby and assuming all other factors remain the same, machine sales decrease by an average of 0.1229905 per day.
```{r }
final_model$coefficients["num_vendex_nearby_300"]
```


### Top and bottom ratio
Ranking all machines according to the final_model, what are the real daily sales of the top20% machines with respect to your model prediction? And the real daily sales of the bottom20% machines according to your model? What’s the top20%/bottom20% ratio?

```{r }
hist(final_model$fitted.values, breaks = 40)
```

```{r}
predictions <- c(predict(final_model, model_data))
real <- c(model_data$daily_sales)

comparison <- data.table(predictions, real)
comparison$ratio <- comparison$predictions/comparison$real
comparison$difference <- comparison$predictions - comparison$real

comparison <- comparison[order(rank(predictions), decreasing = T)]
```
Top 20% predictions
```{r}
comparison[1:(0.2*length(comparison$predictions)),]
```
Bottom 20% predictions
```{r}
comparison[(0.8*length(comparison$predictions)):(length(comparison$predictions))]
```

the real daily sales of the top 20% machines according to model
```{r}
top20 <- mean(comparison$ratio[1:(0.2*length(comparison))])
top20
```
the real daily sales of the bottom20% machines according to model
```{r}
bottom20 <- mean(comparison$ratio[(0.8*length(comparison)):(length(comparison))])
bottom20
```
the top20%/bottom20% ratio
```{r}
top20/bottom20
```
The data tables above show the expected sales for the top 20% machines and for the bottom 20% machines according to our model predictions. The top20%/bottom20% ratio is 2.296307, which means that on average the top 20% machines are expected to sell more than twice as much per day compared to the bottom 20% machines.

#### Choice
Given the following 2 locations for a big machine:
i. Supermarket entrance, 2 nearby hotels of 4 stars, 20 transport routes, no nearby machines
ii. Transport station, no nearby hotels of 4 or 5 stars, 10 transport routes nearby, 3 nearby Vendex machines 
Which location would you choose and why?

```{r}
option1 <- predict(final_model, 
                   data.frame(small_machine=0,income_average=0,log_transport=log(20,base=10),num_hotels_45=2,
                              num_vendex_nearby_300=0,not_trainstation=0))
option2 <- predict(final_model, 
                   data.frame(small_machine=0,income_average=0,log_transport=log(10,base=10),num_hotels_45=0,
                                num_vendex_nearby_300=3,not_trainstation=1))

option1
option2

```
Given the two options for locations taking into account the factors involved in each, we would choose the first option because we predict higher sales for this location (10.16578 instead of 5.978487 in daily sales variable), assuming that both locations cost us the same to acquire and maintain.

