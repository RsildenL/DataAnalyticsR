---
title: "Challenge 2: Introduction to Probability Models"
subtitle: "Data Analytics with R"
author: "Rebecca Silden Langlo, Afonso Penalva, Kevin Ganglbauer, Henrik Mülheims, Martí Pérez & Karmanpreet Singh" 
date: "22/02/2021"
      
output: 
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(MLmetrics)
library(caret)
library(tidyr)
library(pROC)

```

# Predicting Machine Failure

Importing the relevant datasets
```{r Read the datafiles, cache = TRUE}
transaction_data <- fread("Data/transactional_data.csv")
transaction_data$date <- as.Date(transaction_data$date)
machine_failures <- fread("Data/machine_failures.csv")
```


## 1. Merging datasets 
Merge the transactional dataset with the machine failures data set setting failure variable to 0 when no failure is recorded.

```{r merging data}
merged_data <- merge(transaction_data, machine_failures, 
                     by = c("machine", "column", "timestamp"), 
                     all.x = TRUE)

merged_data[is.na(failure), failure :=0]
summary(merged_data)
```
Merging the two datasets results in a data table of 1,840,477 observations and 6 variables, which will be used in the following computations. 'Failure' is '1' on the first sale of a machine after a broken period, and '0' otherwise. An initial inspection of the features shows that the dataset is highly imbalanced regarding observed failures, with a mean of only 0.006. We can also see from the 'date' feature that we have observations from 2017-01-02 until 2017-04-01. 

## 2. Create "last_vend" variable
In the transactional data table, create a variable called “last_vend” containing the timestamp of the previous sale of each machine.
```{r last_vend}
merged_data <- merged_data[order(machine, timestamp)]
merged_data[, last_vend := shift(timestamp, 1), by=.(machine)]
```
A 'last_vend' variable, containing the timestamp of the previous sale of each machine, using the order and shift functions. For the first observations of each of the machines, the 'last_vend' is reported as NA (no previous data).


## 3. Create "deltahours" variable
Create a new variable in the transactional data table called “deltahours” containing, for every sale, the hours that passed since the last sale.
```{r deltahours, cache = TRUE}
merged_data$deltahours <- as.numeric(difftime(merged_data$timestamp, merged_data$last_vend, units = "hours"))
summary(merged_data$deltahours)
```
There are 2495 NA's, which correspond to the first instance of each machine, as there is no previous timestamp available.

The median of 0.59 indicates that half of the machines have a transaction every 35 minutes on average, while the 3rd quantile shows that 75% of the machines have transactions every 2.76 hours. However, the maximum shows that there is a machine with an average of 66 days (1576.13) between the transactions.

## 4. Create auxiliary table called "machine_daily_average"
Create an auxiliary data table called “machine_daily_average” with the average daily sales per machine. 

```{r}
daily_sales <- merged_data[ , .(items_machine_day = uniqueN(timestamp)), by = .(machine, date)]
machine_daily_average <- daily_sales[ ,.(avg_daily_sales = mean(items_machine_day)), by = machine]
head(machine_daily_average)
```
The machine daily average auxiliary table includes the average daily sales for each of the machines. The minimum average daily sales is 2 items and the maximum is 56 items, while most of the machines have average daily sales between 7 and 14 items.

```{r}
merged_data <- merge(merged_data, machine_daily_average, by = 'machine', all.x=TRUE)
summary(merged_data)
```
Including the average daily sales to each of the transactions for the corresponding machine. 

## 5. Create "delta" variable 
Create a new variable called “delta” in the transactional data table containing a normalized version of deltahours consisting on the deltahours associated with each sale divided by the average deltahours of each machine i.e. delta = deltahours/(24/daily_sales_machine). The interpretation of delta is the amount of “missed sales” if the machine was selling at a constant rate

```{r}
merged_data$delta <- merged_data[ ,.(delta = as.numeric(deltahours/(24/avg_daily_sales))),]
summary(merged_data$delta)    
```
The delta variable is the amount of "missed sales" if the machine was selling at a constant rate. 24/daily_sales_machine tells us that on average this much time is spent between buying two consecutive items. So by dividing deltahours by this value, we learn how high our specific purchase frequency was compared to the average purchase frequency of this particular machine.

While most observations have a delta below 1.20, the maximum is 610, indicating that there is at least one machine with a high amount of missed sales.

## 6. Linear logistic regression 
Select 30% of the machines in the transactional data for testing and 70% of the machines for training and train a linear logistic regression model called “m” to predict whether a machine has a failure as a function of variable delta. What is the value of the intercept and the coefficient accompanying variable delta?

```{r}
merged_data <- merged_data %>% drop_na()
summary(merged_data)
```
Given that we have 1,840,477 observations in our dataset, we have decided to drop the 2495 NA values. These NA values resulted from the shift in data from question 2 and removing them still leaves us with a sufficient amount of data.

Test train split: 
```{r, warning=FALSE}
set.seed(12)
index <- sample(x=1:2, size=nrow(merged_data), replace = TRUE, prob=c(0.7, 0.3))
train <- merged_data[index == 1, ] 
test <- merged_data[index == 2, ]

print(paste('Percent of failures in train set: ', round(prop.table(table(train$failure))[2],4)))
print(paste('Percent of failures in train set: ', round(prop.table(table(test$failure))[2],4)))
```
As mentioned above, the dataset is highly imbalanced regarding the target variable "failure", so it is important to keep a similar distribution of failure in the test and training set. 

Logistic regression: 
```{r,warning=FALSE}
m <- glm(failure ~ delta,  data = train, family = "binomial",  na.action = na.omit)
m_predictions <- predict(m, newdata = test, type = "response")
summary(m)$coefficients
```
The logistic regression yields an intercept of -6.9 and a delta coefficient of 0.56, both highly statistically significant. The positive delta coefficient indicates that an increase in delta would increase the probability of predicting 'failure'. This makes sense, since delta is a measure of missing sales calculated based on the average sales for each machine and the time since its last sale.

### a) AUC 
What’s the AUC, a measure of quality, of the model you have built on the train set? and on test set?
```{r, warning=FALSE}
auc_train <- auc(train$failure, m$fitted.values)
auc_test <- auc(test$failure, m_predictions)

print(paste('AUC of model on the training set: ', round(auc_train,4)))
print(paste('AUC of model on the test set: ', round(auc_test,4)))
```
The area under the curve of the training and test set are rather high and close to each other. This is an indication that the model is rather good at predicting machine failures and that it is not overfitted on the training set.

### b) Plot
Plot the function of probability of failure with respect to delta to gain intuition
```{r}
train$delta <- as.numeric(train$delta) 

b0 <- m$coefficients[1]
X1 <- m$coefficients[2]


prob = function(delta) {
  result <- 1/(1+exp(-(b0 + X1*delta)))
}
curve(prob, from = 0, to = 30, n = 500, 
      xlab = "Delta", 
      ylab = "Probability of Failure")
```
We can see in the plot how the presence of failure in Vendex's machines is highly determined in the range in which delta is between 5 and 20, as the probability of failure spikes as we get close to the latter. Any machine with a delta > 20 will have a probability failure notably close to 1.

### c) Alarms 
Let us create alarms with two levels of priority: med-risk and high-risk. Med-risk alarms will fire when the probability of failure is >=60% and High-risk when that probability is >=80%.

#### i) What are the threshold deltas for each type of alarm to fire?
```{r }
f = function(x){1/(1+exp(-(b0 + X1*x)))}-0.6
delta_med <- uniroot(f, c(0, 25))$root

g = function(x){1/(1+exp(-(b0 + X1*x)))}-0.8
delta_high <- uniroot(g, c(0, 25))$root

print(paste('delta_med: ', round(delta_med, 2)))
print(paste('delta_high: ',round(delta_high, 2)))
```
The medium-risk alarm will be activated when delta >= 12.99 and the high-risk alarm will be activated when delta >= 14.73, this is consistent with the plot displayed above.

#### ii) How many of these alarms would be fired per day on average according to your model?
```{r,warning=FALSE}
merged_data[, 'med_risk' := ifelse(delta >= delta_med, 1, 0)]
merged_data[, 'high_risk' := ifelse(delta >= delta_high, 1, 0)]

average_per_day_med <- sum(merged_data$med_risk)/uniqueN(merged_data$date)
average_per_day_high <- sum(merged_data$high_risk)/uniqueN(merged_data$date)

print(paste('Avg. number of medium-risk alarms per day: ', round(average_per_day_med,2)))
print(paste('Avg. number of high-risk alarms per day: ', round(average_per_day_high,2)))
```
The average number of medium-risk alarms fired per day is 41.5 and the average number of high-risk alarms fired per day is 27.82.

#### iii) What % of these will be “false alarms” i.e. failure variable is equal to 0, for each level of priority?
```{r}
med_false_alarm <- merged_data[med_risk == 1, (1-mean(failure)),]*100
high_false_alarm <- merged_data[high_risk == 1, (1-mean(failure)),]*100

print(paste('Percentage of medium-risk alarms that are false alarms: ', round(med_false_alarm, 2)))
print(paste('Percentage of high-risk alarms that are false alarms: ', round(high_false_alarm, 2)))
```
20.67% of the medium-risk alarms fired are going to be false alarms and 8.99% of the fired high-risk alarms are going to be false alarms.

### d) Profit impact
In this exercise we will estimate the profit impact of our EWS system vs the current system:

We created a function that outputs the annual profit we will generate vs the current system as a % of the total profit. The function takes two input parameters: 'x' (the dataframe filtered for either med-risk or high-risk deltas) and 'delta_x' (the delta for either high-risk or med-risk).
```{r}
# First, we filter by the instances that we classified as values with at least a medium risk of failure.
dt_alarm_med = merged_data[delta >= delta_med]
dt_alarm_high = merged_data[delta >= delta_high]# Assumption: Filter both medium and high risk because high risk instances imply having a medium risk of failure as well.

annual_perc_incr <- function(x, delta_x) {
conversion_factor <- 24/x$avg_daily_sales
x[, threshold_hours:=delta_x*conversion_factor]
x[, threshold_hours_fixed := threshold_hours + 1.5]  # 1.5 represents the average time it takes to fix a machine.
x[, delta_fixed:= threshold_hours_fixed * (1/(24/avg_daily_sales))]
x[, won_sales := failure*(delta-delta_fixed)]
add_rev = sum(x$won_sales*1.7) # Additional revenue of the EWS for at least medium risk alarms.
sys_cost = 10*(nrow(x[failure == 0])) # Cost of the system
vendex_cost_prev = uniqueN(merged_data$machine)*2.2*10 # Cost of current system per year (2.2 false alarm per machine per YEAR)
annual_profit_incr = 4*(add_rev - sys_cost ) + vendex_cost_prev # As we are only given data from Jan 1st to April 1st we have to multiply our estimated profit increase by 4 to obtain the actual annual profit increase. The cost of the old system is added to reflect the actual difference in revenue between the systems accounting for the costs of either one. 
perc_incr = (annual_profit_incr/(nrow(merged_data)*1.7*4))*100 # Again, we have to multiply the denominator by 4 so that we receive the annual profit increase in percentage.
return(perc_incr)
}
```

#### i) If we set the EWS only with the med-risk alarms, what is the annual profit we will generate vs the current system as a % of the total profit? [For simplicity, consider the total profit to be the margin per item times the number of items in the period]
```{r}
print(paste('Average annual percentage increase in profit for med-risk EWS: ', round(annual_perc_incr(dt_alarm_med, delta_med),4)))
```

#### ii) And if we set the EWS only with the high-risk alarms?
```{r}
print(paste('Average annual percentage increase in profit for high-risk EWS: ', round(annual_perc_incr(dt_alarm_high, delta_high),4)))

tot_annual_profit = nrow(merged_data)*1.7*4 #profit of all transactions assuming an avg. profit of 1.7 per sale
```

If we configure an EWS for medium-risk alarms instead of relying on the current system we estimate an increase in revenue of 2.40%.
Applying an EWS for high-risk alarms only we forecast an increase in profit of 2.37%.

```{r}
print(paste('Total annual profit: ',
round(tot_annual_profit,0)))
print(paste('Monetary value of 0.03%: ',
round(tot_annual_profit*0.03,0)))
```
We recommend implementing the medium-risk EWS, as the average annual increase in revenue is 0.03% higher than for only high-risk alarms. This difference seems negligible, but in fact equates to $374,948 making the EWS for med-risk alarms the obvious choice from a business point of view.