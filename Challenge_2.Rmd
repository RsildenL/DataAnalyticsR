---
title: "Challenge 2: Introduction to Probability Models"
subtitle: "Data Analytics with R"
author: "Rebecca Silden Langlo, Afonso Penalva, Kevin Ganglbauer, Henrik Mülheims, Martí Pérez & Karmanpreet Singh" 
date: "22/02/2021"
      
output: 
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(MLmetrics)
library(caret)
library(tidyr)
library(pROC)

```

# Predicting Machine Failure

Importing the relevant datasets
```{r Read the datafiles, cache = TRUE}
transaction_data <- fread("Data/transactional_data.csv")
transaction_data$date <- as.Date(transaction_data$date)
machine_failures <- fread("Data/machine_failures.csv")
```


## 1. Merging datasets 
Merge the transactional dataset with the machine failures data set setting failure variable to 0 when no failure is recorded.

```{r merging data}
merged_data <- merge(transaction_data, machine_failures, 
                     by = c("machine", "column", "timestamp"), 
                     all.x = TRUE)

merged_data[is.na(failure), failure :=0]
summary(merged_data)
dim(merged_data)
```
Merging the two datasets results in a 1,840,477 observations of 6 variables, which will be used in the following computations. Failure is 1 on the first sale of a machine after a broken period, and 0 otherwise. An initial inspection of the features shows that the dataset is highly imbalanced regarding observed failures, with a mean of only 0.006. We can also see from the date feature that we have observation from 2017-01-02 until 2017-04-01. 

## 2. Create "last_vend" variable
In the transactional data table, create a variable called “last_vend” containing the timestamp of the previous sale of each machine
Hint: Remember you can use the function “shift” once the data is ordered according to machine and date with function “order” i.e. dt = dt[order(x,y)] where x and y are column names of dt
```{r last_vend}
merged_data <- merged_data[order(machine, timestamp)]
merged_data[, last_vend := shift(timestamp, 1), by=.(machine)]
```
A last_vend variable, containing the timestamp of the previous sale of each machine, using the order and shift functions. For the first observations of each of the machines, an the last_vend is reported as NA.


## 3. Create "deltahours" variable
Create a new variable in the transactional data table called “deltahours” containing, for every sale, the hours that passed since the last sale.
```{r deltahours, cache = TRUE}
merged_data$deltahours <- as.numeric(difftime(merged_data$timestamp, merged_data$last_vend, units = "hours"))
summary(merged_data$deltahours)
```
There are 2495 NA's, which correspond to the first instance of each machine, as there is no previous timestamp available.

The median of 0.59 indicated that half of the machines has on average transaction every 35 minute, while the 3rd quantile shows that 75% of the machines has transactions every 2.76 hour. The maximum however shows that there is a machine with 66 days (1576.13) on average between the transactions.

## 4. Create auxiliary table called "machine_daily_average"
Create an auxiliary data table called “machine_daily_average” with the average daily sales per machine. 
Use this auxiliary table to attach to every row of the transactional data table the the average daily sales per machine. You can do this by doing a merge.
```{r}
daily_sales <- merged_data[ , .(items_machine_day = uniqueN(timestamp)), by = .(machine, date)]
machine_daily_average <- daily_sales[ ,.(avg_daily_sales = mean(items_machine_day)), by = machine]
head(machine_daily_average)


#check if the numbers are correct (compare with other teams)
#comment on distribution of daily sales etc. 
```
The machine daily average auxiliary table includes the average daily sales for each of the machines. The minimum average daily sales is 2 items, the maximum is 56 items, while most of the machines has on average daily sales between 7 and 14 items. 

```{r}
merged_data <- merge(merged_data, machine_daily_average, by = 'machine', all.x=TRUE)
summary(merged_data)
```
Including the average daily sales to each of the transaction for the corresponding machine. 

## 5. Create "delta" variable 
Create a new variable called “delta” in the transactional data table containing a normalized version of deltahours consisting on the deltahours associated with each sale divided by the average deltahours of each machine i.e. delta = deltahours/(24/daily_sales_machine). The interpretation of delta is the amount of “missed sales” if the machine was selling at a constant rate

```{r}
merged_data$delta <- merged_data[ ,.(delta = as.numeric(deltahours/(24/avg_daily_sales))),]
summary(merged_data$delta)    
```
The delta variable is the amount of "missed sales" if the machine was selling at a constant rate. (24/daily_sales_machine) tells us that on an average this much time is spent between buying two consecutive items. So dividing deltahours with this will tell us how was our specific purchase frequency compared to average purchase frequency of that particular machine.

While most observations have a delta below 1.20, is the maximum 610 indicating that there is at least one machine with high amount of missed sales.

# Creating the model 

## 6. Linear logistic regression 
Select 30% of the machines in the transactional data for testing and 70% of the machines for training and train a linear logistic regression model called “m” to predict whether a machine has a failure as a function of variable delta. What is the value of the intercept and the coefficient accompanying variable delta?

```{r}
merged_data <- merged_data %>% drop_na()
summary(merged_data)
```
Given that we have 1,840,477 observations in our dataset, we have decided to drop the 2495 NA values. These NA values resulted from the shift in data from question 2.

Test train split: 
```{r, warning=FALSE}
set.seed(12)
index <- sample(x=1:2, size=nrow(merged_data), replace = TRUE, prob=c(0.7, 0.3))
train <- merged_data[index == 1, ] 
test <- merged_data[index == 2, ]

message('Percent of failures in train set: ', round(prop.table(table(train$failure))[2],4))
message('Percent of failures in train set: ', round(prop.table(table(test$failure))[2],4))
```
As noted above is the dataset highly imbalanced regaring the target variable "failure", it is therefore important to keep a similar distribution of failure in the test and training set. 

Logistic regression: 
```{r,warning=FALSE}
m <- glm(failure ~ delta,  data = train, family = "binomial",  na.action = na.omit)
m_predictions <- predict(m, newdata = test, type = "response")
summary(m)$coefficients
```
The logistic regression results in a intercept of -6.9 and a delta coefficient of 0.56, both highly statistical significant. The positive delta coefficient indicatesthat an increase in delta would inccrease the likelyhood of predicting failure. This makes intuitive sense, since the delta is a measure of missing sales calculated based on the average sales for the machine and time since last salein this machine. 

### a) AUC 
What’s the AUC, a measure of quality, of the model you have built on the train set? and on test set?
```{r}
auc_train <- auc(train$failure, m$fitted.values)
auc_test <- auc(test$failure, m_predictions)

message('AUC of model on the training set: ', round(auc_train,4))
message('AUC of model on the test set: ', round(auc_test,4))
```
The area under the curve of the training and test set are rather high and close to eachother. This is a sign that the model is rather good at predicting machine failures and that the model is not overfitted on the trainingset. s

### b) Plot
Plot the function of probability of failure with respect to delta to gain intuition
```{r}
#range(merged_data$delta, na.rm = TRUE) 
train$delta <- as.numeric(train$delta) 

b0 <- m$coefficients[1]
X1 <- m$coefficients[2]

#typeof(m$coefficients)
prob = function(delta) {
  result <- 1/(1+exp(-(b0 + X1*delta)))
#  print(result)
}
curve(prob, from = 0, to = 30, n = 500, 
      xlab = "Delta", 
      ylab = "Probability of Failure")
```

### c) Alarms 
Let us create alarms with two levels of priority: med-risk and high-risk. Med-risk alarms will fire when the probability of failure is >=60% and High-risk when that probability is >=80%.
#### i) The threshold delta for each alarm to fire
```{r }
f = function(x){1/(1+exp(-(b0 + X1*x)))}-0.6
delta_med <- uniroot(f, c(0, 25))$root

g = function(x){1/(1+exp(-(b0 + X1*x)))}-0.8
delta_high <- uniroot(g, c(0, 25))$root

message('delta_med: ', round(delta_med, 2)
message('delta_high: ',round(delta_high, 2))
```
The medium-risk alarm will be activated when delta >= 12.99263 and the high-risk alarm will be activated when delta >= 14.73126.

#### ii) Number of alarms per day
```{r,warning=FALSE}
merged_data[, 'med_risk' := ifelse(delta >= delta_med, 1, 0)]
merged_data[, 'high_risk' := ifelse(delta >= delta_high, 1, 0)]

average_per_day_med <- sum(merged_data$med_risk)/uniqueN(merged_data$date)
average_per_day_high <- sum(merged_data$high_risk)/uniqueN(merged_data$date)

message('Avg. number of medium-risk alarms per day: ', round(average_per_day_med,2))
message('Avg. number of high-risk alarms per day: ', round(average_per_day_high,2))
```

#### iii) Percentage of false alarms
```{r}
med_false_alarm <- merged_data[med_risk == 1, (1-mean(failure)),]*100
high_false_alarm <- merged_data[high_risk == 1, (1-mean(failure)),]*100

message('Percentage of medium-risk alarms that are false alarms: ', round(med_false_alarm, 2))
message('Percentage of high-risk alarms that are false alarms: ', round(high_false_alarm, 2))
```

### d) Profit impact
In this exercise we will estimate the profit impact of our EWS system vs the current system:
```{r}
# First, we filter by the instances that we classified as values with at least a medium risk of failure.
dt_alarm_med = merged_data[delta >= delta_med]
dt_alarm_high = merged_data[delta >= delta_high]# Assumption: Filter both medium and high risk because high risk instances imply having a medium risk of failure as well.

annual_perc_incr <- function(x, delta_x) {
conversion_factor <- 24/x$avg_daily_sales
x[, threshold_hours:=delta_x*conversion_factor]
x[, threshold_hours_fixed := threshold_hours + 1.5]  # The 1.5 stands for the average time it takes to fix a machine.
x[, delta_fixed:= threshold_hours_fixed * (1/(24/avg_daily_sales))]
x[, won_sales := failure*(delta-delta_fixed)]
add_rev = sum(x$won_sales*1.7) # Additional revenue of the EWS for at least medium risk alarms.
sys_cost = 10*(nrow(x[failure == 0])) # Cost of the system
vendex_cost_prev = uniqueN(merged_data$machine)*2.2*10 # Cost of current system per year (2.2 false alarm per machine per YEAR)
annual_profit_incr = 4*(add_rev - sys_cost ) - vendex_cost_prev # As we are only given data from Jan 1st to April 1st we have to multiply our estimated profit increase by 4 to obtain the actual annual profit increase.
perc_incr = (annual_profit_incr/(nrow(merged_data)*1.7*4))*100 # Again, we have to multiply the denominator by 4 so that we receive the annual profit increase in percentage.
return(perc_incr)
}

## i. If we set the EWS only with the med-risk alarms, what is the annual profit we will generate vs the current system as a % of the total profit? [For simplicity, consider the total profit to be the margin per item times the number of items in the period]
message('Average annual percentage increase in revenue for med-risk EWS: ', round(annual_perc_incr(dt_alarm_med, delta_med),4))

## ii. And if we set the EWS only with the high-risk alarms?
message('Average annual percentage increase in revenue for high-risk EWS: ', round(annual_perc_incr(dt_alarm_high, delta_high),4))
```
If we configure an EWS for medium risk alarms instead of relying on the current system we estimate an increase in revenue of 1.52%.
Applying an EWS for high risk alarms only we forecast an increase in revenue of 1.49%. We recommend implementing the medium-risk EWS, as the average annual increase in revenue is 0.03% higher. 